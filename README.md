# FileRAG
文件RAG
FileRAG和目前市场上大多数的RAG方案不同的点主要是不进行文档切片，而是利用长文档大模型的能力，通过引导式对话定位到某个文档然后进行文档对话，所以这套方案主要是适应一些特殊场景，如在实际落地过程中有个客户的数据就可以很好的适应这种场景，所以才采用这套方案。
目前市场上的RAG方案大多采用文档分片的方式进行向量化存储，如下图：
<img width="1151" alt="1" src="https://github.com/user-attachments/assets/7b104891-3e4f-4ba5-96bf-8dadc3d809a0" />


采用上面的方式会导致了一个明显的问题：每个片段的信息可能不完整，从而使得召回的相关片段也无法提供全面的信息，并且当文档内容太过专业，会导致召回、重排无法选出真正正确的知识片段。
在给某个客户落地RAG的时候发现客户的数据情况为几万份维修手册，每份手册在2千字到1万字左右，用户的问题都是可以在某几个手册里找到对应的答案，后面就想到下面的方案：
![image](https://github.com/user-attachments/assets/dce6b7b5-57fc-4651-8761-f2e8cacc9306)


在一开始文档数据导入的时候就会导入文档的三份数据：
整篇文档内容：核心数据，提取文档里完整内容进行保存
文档级索引描述：介绍文档里的内容，如果没有后面定位文档内容则使用整篇文档内容进行定位
文档内容介绍：可选项、主要针对一些企业内部专业知识，大模型无法理解的内容可以进行额外信息进行补充
上面的三份数据会导入到某个知识库中，这个知识库可以一个也可以多个，主要是作为分类和后续定位作用，通过知识库级索引描述可以进行一次前置定位先定位到某个知识库再定位知识库的某个文档，而知识库级专业知识则是作为企业知识的补充，主要是为了让一些通用的企业专有名词能在问答的时候一起给到大模型。
后续当用户提供的时候 会先通过问题查询知识库级的索引和文档级的索引来查询到文档内容，然后让大模型进行判断答案是否在某N个文档中，如果有超过N个文档的情况则返回相关内容让用户进行确认，如下：
![image](https://github.com/user-attachments/assets/6e74c682-fa7c-4104-aa5b-52b553b9cbb2)

通过引导式提问一步步明确用户的问题，大模型通过问题重构，确认用户最终的问题为A100的机器风扇不转，通过这个问题就可以定位到某N个文档，之后把文档的整篇内容和相关数据一起给到大模型进行文档对话，在这个阶段就已经把所有相关资料给到大模型了。



